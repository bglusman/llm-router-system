version: '3.9'

services:
  router:
    build: .
    ports:
      - "8080:8080"
    depends_on:
      - vosk
      - tts
      - llama

  vosk:
    image: alphacep/kaldi-vosk-server:latest
    ports:
      - "2700:2700"
    # Example model volume mount (user must supply path)
    volumes:
      - ./models/vosk:/model

  tts:
    image: coqui/tts
    ports:
      - "5002:5002"

  llama:
    image: ghcr.io/ggerganov/llama.cpp:latest
    ports:
      - "8081:8080"
    volumes:
      - ./models/llama:/models

  homeassistant:
    image: ghcr.io/home-assistant/home-assistant:stable
    ports:
      - "8123:8123"
    volumes:
      - homeassistant-data:/config

volumes:
  homeassistant-data:
